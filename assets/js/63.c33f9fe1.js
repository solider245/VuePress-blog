(window.webpackJsonp=window.webpackJsonp||[]).push([[63],{386:function(s,t,a){"use strict";a.r(t);var n=a(25),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#安装环境"}},[s._v("安装环境")])]),a("li",[a("a",{attrs:{href:"#创建scrapy项目"}},[s._v("创建Scrapy项目")])]),a("li",[a("a",{attrs:{href:"#描述一个爬虫"}},[s._v("描述一个爬虫")])]),a("li",[a("a",{attrs:{href:"#使用shell方式进行页面测试"}},[s._v("使用shell方式进行页面测试")])]),a("li",[a("a",{attrs:{href:"#分析页面"}},[s._v("分析页面")]),a("ul",[a("li",[a("a",{attrs:{href:"#电影排行榜页面"}},[s._v("电影排行榜页面")])]),a("li",[a("a",{attrs:{href:"#电影评论页面"}},[s._v("电影评论页面")])])])]),a("li",[a("a",{attrs:{href:"#实现思路"}},[s._v("实现思路")])]),a("li",[a("a",{attrs:{href:"#启动爬虫"}},[s._v("启动爬虫")])]),a("li",[a("a",{attrs:{href:"#小结"}},[s._v("小结")])])])]),s._v(" "),a("a",{attrs:{href:"https://ihades.cn/post/12/",target:"_blank",rel:"noopener noreferrer"}},[s._v("原文链接"),a("OutboundLink")],1),a("p"),s._v(" "),a("p",[a("a",{attrs:{href:"https://scrapy.org/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy"),a("OutboundLink")],1),s._v("是一个纯Python语言实现的爬虫框架，简单、易用、拓展性高使得其成为Python爬虫中的主流利器，本文以目前官方最新的版本"),a("strong",[s._v("1.6")]),s._v("为基础，展开从简单使用到深入原理的探讨。")]),s._v(" "),a("p",[s._v("提前说一下教程归教程，总归还是没有官方文档讲的贴切！如果读者阅读完本文对Scrapy产生了兴趣并原意更深入了解Scrapy的话，请一定养成随时翻阅官方文档的习惯！")]),s._v(" "),a("p",[a("a",{attrs:{href:"https://docs.scrapy.org/en/latest/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy官方文档"),a("OutboundLink")],1)]),s._v(" "),a("p",[s._v("本文主要阐述以下内容")]),s._v(" "),a("ul",[a("li",[s._v("为什么选择Scrapy？")]),s._v(" "),a("li",[s._v("Hello Scrapy！（实践）")]),s._v(" "),a("li",[s._v("Scrapy如何工作的？")])]),s._v(" "),a("p",[s._v("对于第一小节『为什么选择Scrapy』建议读者都能阅览一下，我会分析一下我对Scrapy的业务场景的理解。")]),s._v(" "),a("p",[s._v("对于余下的两个小节，我原意是将『Scrapy是如何工作的』放在『Hello Scrapy』之前去讲的，但是考虑到并非所有人都愿意一上来就了解理论性的东西，所以就先把实践性的小Demo放在前面讲，希望以此引起读者的兴趣，兴趣能让我们更深入的了解一件事。因此我就把『Scrapy如何工作』这一节放在最后讲，也可以承接下一章的Scrapy原理！")]),s._v(" "),a("p",[s._v("虽然Scrapy已经被设计的能够满足绝大多数的爬虫工作，但还是有一些场景其实并不适用。")]),s._v(" "),a("ul",[a("li",[s._v("什么情况Scrapy不是首选？")])]),s._v(" "),a("ol",[a("li",[a("p",[s._v("当你的爬取页面数量很少，针对的站点规模很小的时候，Scrapy并不是首选。例如爬取点电影榜单，某些新闻资讯等等，Requests+PyQuery这种方式就已经能够很好的完成此类任务，产生的代码量比Scrapy少，并且从网络请求效率以及网页解析速度上Requests和PyQuery都比Scrapy自带的两个模块要好！")])]),s._v(" "),a("li",[a("p",[s._v("没有通用性爬虫需求时，Scrapy可选可不选。在我看来Scrapy真正的好处在于能够针对多种不同类型的网站定制相应的『Spider动作』，强大的『ItemLoader』能够对数据输入输出定义一系列的处理动作。假如你没有需要不断的拓展信息源的需求，Scrapy其实并不能发挥最大的能力！")])]),s._v(" "),a("li",[a("p",[s._v("当你需要增量爬取数据时，Scrapy显得很无力。Scrapy并没有增量爬取的功能实现，因为增量的难度不一样，如果简单需求对Scrapy进行小手术估计就能完成了，但是如果是增量要求高的话，可能Scrapy真的动起来很麻烦！")])])]),s._v(" "),a("p",[a("strong",[s._v("注意：以上三种情况只是想说明Scrapy不是首选，并没有说不建议用！只是希望读者能够明白在选择一个框架或技术的时候不是跟风，在设计之初就考虑慎重对项目的良好发展有很大的益处。")])]),s._v(" "),a("ul",[a("li",[s._v("什么情况Scrapy很好用？")])]),s._v(" "),a("ol",[a("li",[a("p",[s._v("需要分布式设计时，Scrapy的非官方组件Scrapy-redis很好用。Scrapy本身也并不能实现分布式机制，但是使用rmax所开发的"),a("a",{attrs:{href:"https://github.com/rmax/scrapy-redis",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scrapy-redis"),a("OutboundLink")],1),s._v("就可以实现分布式，后面我也会慢慢讲到。")])]),s._v(" "),a("li",[a("p",[s._v("有可拓展需求时，Scrapy是利器。具体原因在上面已经阐述过，这里就不多做解释了。")])])]),s._v(" "),a("p",[a("strong",[s._v("注意：以上所有情况均来自我个人使用Scrapy时的总结，仅供参考！")])]),s._v(" "),a("p",[s._v("Demo以豆瓣（万古爬虫受害者）热门电影排行榜以及其所有评论为实验目标，一一讲述Scrapy的基本功能，相信读者在实践完这个Demo之后，就能很好的使用Scrapy了。")]),s._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/GeekHades1/scrapy_douban_demo/tree/master/douban_demo",target:"_blank",rel:"noopener noreferrer"}},[s._v("项目gitHub"),a("OutboundLink")],1)]),s._v(" "),a("p",[s._v("需要安装:")]),s._v(" "),a("ul",[a("li",[s._v("python (本文所使用的是3.7)")]),s._v(" "),a("li",[s._v("scrapy")])]),s._v(" "),a("h2",{attrs:{id:"安装环境"}},[s._v("安装环境")]),s._v(" "),a("ul",[a("li",[s._v("安装Scrapy")])]),s._v(" "),a("p",[s._v("命令行中键入"),a("code",[s._v("pip install scrapy")])]),s._v(" "),a("h2",{attrs:{id:"创建scrapy项目"}},[s._v("创建Scrapy项目")]),s._v(" "),a("p",[s._v("在命令行中键入"),a("code",[s._v("scrapy startproject douban_demo")]),s._v("，结果如下图所示")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2019/6/9/16b3a136c8c72ee1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1",alt:""}})]),s._v(" "),a("p",[s._v("之后可以看到Scrapy还提示我们可以使用"),a("code",[s._v("genspider")]),s._v("这个命令来创建我们的爬虫文件，在这之前我们先来看看刚刚那条命令执行完之后发生了什么。")]),s._v(" "),a("p",[s._v("查看文件目录。我们可以看到如下信息")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("douban_demo\n├── douban_demo\n│   ├── items.py       \n│   ├── middlewares.py \n│   ├── pipelines.py   \n│   ├── settings.py    \n│   └── spiders        \n└── scrapy.cfg         \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])]),a("p",[s._v("大致了解每个文件用途之后，接下来我们就开始我们的爬虫之旅吧。")]),s._v(" "),a("h2",{attrs:{id:"描述一个爬虫"}},[s._v("描述一个爬虫")]),s._v(" "),a("p",[s._v("使用"),a("code",[s._v("scrapy genspider douban douban.com")]),s._v("来新建一个爬虫文件，这个新建的爬虫文件会被放入"),a("code",[s._v("douban_demo/spiders")]),s._v("底下。")]),s._v(" "),a("p",[a("strong",[s._v("PS："),a("code",[s._v("genspider")]),s._v("的用法"),a("code",[s._v("scrapy genspider [options] <name> <domain>")])])]),s._v(" "),a("p",[s._v("此时"),a("code",[s._v("douban.py")]),s._v("文件就会出现在"),a("code",[s._v("spiders")]),s._v("底下，初始内容如下:")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DoubanSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'douban'")]),s._v("                       \n    allowed_domains "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'douban.com'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("      \n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'http://douban.com/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   \n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("            \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("p",[s._v("在Scrapy项目中你所有的Spider类都必须得继承"),a("code",[s._v("scrapy.Spider")]),s._v("，其中"),a("code",[s._v("name")]),s._v("、"),a("code",[s._v("start_urls")]),s._v("以及"),a("code",[s._v("parse")]),s._v("成员方法是每个Spider类必须要声明的。更多的Spider属性以及成员方法可以"),a("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/spiders.html?highlight=Spider",target:"_blank",rel:"noopener noreferrer"}},[s._v("点击此链接"),a("OutboundLink")],1)]),s._v(" "),a("p",[s._v("接下来只要将我们的爬取对象链接放入"),a("code",[s._v("start_urls")]),s._v("里面就可以，我们以"),a("code",[s._v("https://movie.douban.com/chart")]),s._v("为实验对象。")]),s._v(" "),a("p",[s._v("将"),a("code",[s._v("DoubanSpider")]),s._v("中的"),a("code",[s._v("start_urls")]),s._v("的值替换为 "),a("code",[s._v("start_urls = ['https://movie.douban.com/chart']")])]),s._v(" "),a("h2",{attrs:{id:"使用shell方式进行页面测试"}},[s._v("使用shell方式进行页面测试")]),s._v(" "),a("p",[s._v("Scrapy还给我们提供了"),a("code",[s._v("shell")]),s._v("命令供我们在"),a("code",[s._v("shell")]),s._v("中进行页面数据提取测试，这比requests+pyquery的方式要高效。")]),s._v(" "),a("p",[s._v("命令格式:"),a("code",[s._v("scrapy shell urls")])]),s._v(" "),a("p",[s._v("在命令行里键入"),a("code",[s._v("scrapy shell")]),s._v("进入"),a("code",[s._v("shell")]),s._v("模式。")]),s._v(" "),a("p",[a("strong",[s._v("注意：此时不要着急添加urls，因为我们的测试对象有对UA进行检测，如果直接入测试链接会出现403。至于在什么目录输入这条命令不做具体限制。")])]),s._v(" "),a("p",[s._v("输出内容如下：")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("venv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" ➜  douban_demo scrapy shell --nolog                                 \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" Available Scrapy objects:\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   scrapy     scrapy module "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("contains scrapy.Request, scrapy.Selector, etc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   crawler    "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("scrapy.crawler.Crawler object at 0x106c5c55"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[s._v("0")]),s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   item       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   settings   "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("scrapy.settings.Settings object at 0x108e1889"),a("span",{pre:!0,attrs:{class:"token operator"}},[a("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[s._v("8")]),s._v(">")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" Useful shortcuts:\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   fetch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("redirect")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("True"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" Fetch URL and update "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("local")]),s._v(" objects "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("by default, redirects are followed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   fetch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("req"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                  Fetch a scrapy.Request and update "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("local")]),s._v(" objects \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   shelp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("           Shell "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("help")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("print this "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("help")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("   view"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    View response "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" a browser\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("p",[s._v("此时我们就可以看到已经进入了类似Python命令行交互器一样的界面，首先我们为了防止豆瓣403应该在"),a("code",[s._v("settings")]),s._v("里面加入"),a("code",[s._v("DEFAULT_REQUEST_HEADERS")]),s._v("属性，这是一个请求头字典，只要Scrapy检测到有这个选项都会将里面的值加入到请求头中。")]),s._v(" "),a("p",[s._v("值如下：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("DEFAULT_REQUEST_HEADERS "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Accept'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Accept-Language'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'en'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'user-agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 'Mozilla"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Macintosh"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" Intel Mac OS X 10_14_5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" AppleWebKit"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("537.36")]),s._v(" \\\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("KHTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" like Gecko"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" Chrome"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("74.0")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".3729")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".169")]),s._v(" Safari"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("537.36")]),s._v("'\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("在交互界面中键入一下内容即可添加默认请求头")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" settings.DEFAULT_REQUEST_HEADERS "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".   "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Accept'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'")]),s._v(",\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".   "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Accept-Language'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'en'")]),s._v(",\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(".   "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'user-agent'")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 \\\n...   (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("再次输入"),a("code",[s._v("settings.DEFAULT_REQUEST_HEADERS")]),s._v("查看是否添加成功。")]),s._v(" "),a("p",[s._v("配置完成后我们就可以使用"),a("code",[s._v("fetch(urls)")]),s._v("命令来抓取我们需要测试的页面了")]),s._v(" "),a("p",[s._v("键入"),a("code",[s._v("fetch('https://movie.douban.com/chart')")]),s._v("即可看到一下内容")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2019")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("engine"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" INFO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" Spider opened\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2019")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("engine"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" DEBUG"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" Crawled "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("GET https"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v("movie"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("douban"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("robots"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("txt"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("referer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2019")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("06")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("engine"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" DEBUG"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" Crawled "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("GET https"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v("movie"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("douban"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("com"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("chart"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("referer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("从日志中我们可以看到已经成功获取了目标页面，在获取页面之前我们还可以知道scrapy先访问了"),a("code",[s._v("robots.txt")]),s._v("文件，这是一个良好的爬虫习惯，此时scrapy的所有页面获取都将会遵从"),a("code",[s._v("robots.txt")]),s._v("里面的规则，如果你不想遵从这一规则可以在"),a("code",[s._v("settings")]),s._v("里配置"),a("code",[s._v("ROBOTSTXT_OBEY = False")]),s._v("。")]),s._v(" "),a("p",[s._v("此时你可以使用"),a("code",[s._v("response.text")]),s._v("来检查我们是否获取了整个页面的源码。 scrapy的所有资源解析操作都被集成在了"),a("code",[s._v("response")]),s._v("这个对象中，更多的"),a("code",[s._v("response")]),s._v("介绍可以"),a("a",{attrs:{href:"https://docs.scrapy.org/en/latest/topics/request-response.html?highlight=response#response-subclasses",target:"_blank",rel:"noopener noreferrer"}},[s._v("点击此链接"),a("OutboundLink")],1)]),s._v(" "),a("h2",{attrs:{id:"分析页面"}},[s._v("分析页面")]),s._v(" "),a("h3",{attrs:{id:"电影排行榜页面"}},[s._v("电影排行榜页面")]),s._v(" "),a("p",[s._v("对页面进行元素检查")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2019/6/9/16b3a136ce33d3a5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1",alt:""}})]),s._v(" "),a("p",[s._v("可以看到我们需要爬取的内容在"),a("code",[s._v("table")]),s._v("里面。因为页面有多个"),a("code",[s._v("table")]),s._v("，因此只需要对其迭代获取即可。")]),s._v(" "),a("p",[s._v("在"),a("code",[s._v("shell")]),s._v("中使用"),a("code",[s._v("response.css('table')")]),s._v("即可获取所有的"),a("code",[s._v("table")]),s._v("元素，本文全部采用"),a("code",[s._v("css selector")]),s._v("进行元素选择，"),a("code",[s._v("xpath")]),s._v("也可自行切换。")]),s._v(" "),a("p",[s._v("每个电影的信息都在"),a("code",[s._v("table")]),s._v("标签底下的"),a("code",[s._v("tr.item")]),s._v("里面。")]),s._v(" "),a("p",[s._v("电影的详情链接可以使用"),a("code",[s._v("a.nbg::attr(href)")]),s._v("来获取")]),s._v(" "),a("p",[s._v("电影图片我们可以使用"),a("code",[s._v("a.nbg > img::attr(src)")]),s._v("来获取")]),s._v(" "),a("p",[s._v("对于电影名字处理稍显复杂，从上图可以看出电影可能拥有多个名字，都被包裹在"),a("code",[s._v("div.pl2 > a")]),s._v("底下，其中其他名字在"),a("code",[s._v("div.pl2 > a > span")]),s._v("底下，因此我们需要对名字进行一些格式处理，例如去掉空格、换行符等等。")]),s._v(" "),a("p",[s._v("因此影名可以使用"),a("code",[s._v("div.pl2 > a::text")]),s._v("和"),a("code",[s._v("div.pl2 > a > span::text")]),s._v("分别获取，但是因此"),a("code",[s._v("div.pl2")]),s._v("底下的"),a("code",[s._v("a")]),s._v("标签较多，我们只需要取得第一个即可使用"),a("code",[s._v("extract_first()")]),s._v("方法即可取出第一个"),a("code",[s._v("Selector")]),s._v("元素的内容并转换为"),a("code",[s._v("str")]),s._v("。")]),s._v(" "),a("p",[s._v("电影简介只需要使用"),a("code",[s._v("p.pl::text")]),s._v("中获取即可")]),s._v(" "),a("h3",{attrs:{id:"电影评论页面"}},[s._v("电影评论页面")]),s._v(" "),a("p",[s._v("在相应的电影详细信息链接后拼接"),a("code",[s._v("comments?status=P")]),s._v("即可进入电影影评页面。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2019/6/9/16b3a136cda769cd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1",alt:""}})]),s._v(" "),a("p",[s._v("可以看出影评数据由多个"),a("code",[s._v("comment-item")]),s._v("组成，影评内容都被包裹在"),a("code",[s._v("div.comment")]),s._v("底下，因此按照上面的分析方法也能找出相应数据的获取方式。这里就不在阐述")]),s._v(" "),a("h2",{attrs:{id:"实现思路"}},[s._v("实现思路")]),s._v(" "),a("ol",[a("li",[a("p",[s._v("分别创建两个"),a("code",[s._v("parse")]),s._v("方法："),a("code",[s._v("parse_rank")]),s._v("和"),a("code",[s._v("parse_comments")]),s._v("，"),a("code",[s._v("parse_rank")]),s._v("负责处理电影排行榜页面，"),a("code",[s._v("parse_comments")]),s._v("负责处理相应的评论页面。")])]),s._v(" "),a("li",[a("p",[s._v("重写"),a("code",[s._v("Spider")]),s._v("类的"),a("code",[s._v("start_requests")]),s._v("方法，填充"),a("code",[s._v("url")]),s._v("以及"),a("code",[s._v("callback")]),s._v("属性值，由于要先通过电影排行榜页面获取详情信息才可获取想关评论地址，所以在"),a("code",[s._v("start_requests")]),s._v("中返回的"),a("code",[s._v("Request callback")]),s._v("属性应该填充为"),a("code",[s._v("self.parse_rank")])])]),s._v(" "),a("li",[a("p",[s._v("在"),a("code",[s._v("parse_rank")]),s._v("中处理返回的"),a("code",[s._v("reponse")]),s._v("，按照『分析页面』中的思路去解析数据并且使用"),a("code",[s._v("yield")]),s._v("抛出评论页面的"),a("code",[s._v("Request")]),s._v("，"),a("code",[s._v("callback")]),s._v("属性填充为"),a("code",[s._v("self.parse_comments")])])]),s._v(" "),a("li",[a("p",[s._v("在"),a("code",[s._v("parse_comments")]),s._v("方法中处理返回的评论页面，抛出数据以及下一页链接。")])])]),s._v(" "),a("p",[a("strong",[s._v("注："),a("code",[s._v("Spider parse")]),s._v("方法：所有的"),a("code",[s._v("parse")]),s._v("方法都必须返回Item(目前可以理解为数据项)或者Requests(下一条请求)。这里所有的"),a("code",[s._v("parse")]),s._v("的意思是不是特指"),a("code",[s._v("Spider")]),s._v("类中生成的"),a("code",[s._v("parse")]),s._v("方法，而是所有具备解析功能的函数都应该返回Item或者Requests。")])]),s._v(" "),a("p",[s._v("代码示例")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("request "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Request\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DoubanSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'douban'")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("start_requests")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'https://movie.douban.com/chart'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse_rank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse_rank")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" item "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'tr.item'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            detail_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a.nbg::attr(href)'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            img_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a.nbg > img::attr(src)'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            main_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'div.pl2 > a::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            other_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'div.pl2 > a > span::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            brief "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'p.pl::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            main_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" main_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'\\n'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("' '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'detail_url'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" detail_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'img_url'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" img_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" main_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("other_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'brief'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" brief\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("detail_url"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'comments?status=P'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                          callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse_comments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                          meta"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'movie'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" main_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse_comments")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" comments "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.comment-item'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            username "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" comments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'span.comment-info > a::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            comment "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" comments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'span.short::text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'movie'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("meta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'movie'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'username'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" username"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'comment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" comment\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        nexturl "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("css"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a.next::attr(href)'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" nexturl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'?'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("nexturl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                          callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse_comments"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                          meta"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("meta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br")])]),a("h2",{attrs:{id:"启动爬虫"}},[s._v("启动爬虫")]),s._v(" "),a("p",[s._v("一切准备就绪，我们就可以在"),a("code",[s._v("douban_demo")]),s._v("(最顶级的)目录底下键入命令 "),a("code",[s._v("scrapy crawl douban")]),s._v("就可以看到有许多的日志数据并且还打印出了许多电影信息以及评论内容。")]),s._v(" "),a("p",[s._v("到此我们就对豆瓣电影排行以及评论完成了初步的抓取，当然豆瓣限制了非登陆用户可以查看的评论数以及检测爬虫行为等等，这些反爬机制我们日后再讲。")]),s._v(" "),a("p",[s._v("那么现在有一个问题是我需要将数据保存应该如何做呢？")]),s._v(" "),a("p",[s._v("Scrapy提供了许多"),a("code",[s._v("Feed exports")]),s._v("的方法，可以将输出数据保存为"),a("code",[s._v("json, json lines, csv, xml")])]),s._v(" "),a("p",[s._v("在启动命令后面加"),a("code",[s._v("-o xx.json")]),s._v("就可以将文件保存为"),a("code",[s._v("json")]),s._v("格式。")]),s._v(" "),a("p",[s._v("如："),a("code",[s._v("scrapy crawl douban -o result.json")])]),s._v(" "),a("p",[s._v("因为数据有中文内容，scrapy在使用"),a("code",[s._v("json encoder")]),s._v("的时候默认所有数据均是"),a("code",[s._v("ascii")]),s._v("的，因此我们需要将数据编码设置为"),a("code",[s._v("utf-8")]),s._v("。")]),s._v(" "),a("p",[s._v("只需在"),a("code",[s._v("settings.py")]),s._v("中加入"),a("code",[s._v("FEED_EXPORT_ENCODING = 'utf-8'")]),s._v("即可。")]),s._v(" "),a("p",[s._v("这时候在此数据即可看到中文正常显示。")]),s._v(" "),a("p",[s._v("此时大约会产生2000条数据。")]),s._v(" "),a("h2",{attrs:{id:"小结"}},[s._v("小结")]),s._v(" "),a("p",[s._v("到此我们已经完成了对豆瓣电影及影评的初步抓取，虽然能够成功抓取数据，但给人的感觉就是『我仅仅只是编写了解析网页的代码以及键入启动爬虫命令，结果Scrapy就能够帮我完成从网页请求到数据产出所有的任务』，我们得继续探究当我们键入了"),a("code",[s._v("scrapy crawl douban -o result.json")]),s._v("这一条启动命令后Scrapy到底做了什么。")]),s._v(" "),a("p",[s._v("请各位原意了解Scrapy的读者保存下图，此图对Scrapy的学习尤为关键。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://user-gold-cdn.xitu.io/2019/6/9/16b3a136ce1b2ef0?imageView2/0/w/1280/h/960/format/webp/ignore-error/1",alt:""}})]),s._v(" "),a("p",[s._v("根据此图分析，当我们键入"),a("code",[s._v("scrapy crawl douban -o result.json")]),s._v("之后，Scrapy做了以下工作")]),s._v(" "),a("ol",[a("li",[a("p",[a("code",[s._v("Crawler")]),s._v("接收到"),a("code",[s._v("crawl")]),s._v("指令后便会被启动，激活"),a("code",[s._v("name")]),s._v("为"),a("code",[s._v("douban")]),s._v("的"),a("code",[s._v("Spider")]),s._v("，同时创建"),a("code",[s._v("Engine")]),s._v("，此时我们的"),a("code",[s._v("DoubanSpider")]),s._v("就被启动。")])]),s._v(" "),a("li",[a("p",[s._v("当"),a("code",[s._v("DoubanSpider")]),s._v("被新建之后，"),a("code",[s._v("Engine")]),s._v("就会检测"),a("code",[s._v("Spider")]),s._v("的请求队列，也就是我们的"),a("code",[s._v("start_urls")]),s._v("属性or"),a("code",[s._v("start_requests")]),s._v("方法。这两者都必须是可迭代对象，因此可以理解我们的示例代码中"),a("code",[s._v("start_requests")]),s._v("方法为何是使用"),a("code",[s._v("yield")]),s._v("抛出。此时生成"),a("code",[s._v("Request")]),s._v("对象，所有"),a("code",[s._v("Request")]),s._v("对象都会先经过"),a("code",[s._v("Spider Middlewares")]),s._v("这个中间件，现阶段我们只需要将中间件理解为一座座桥，我们现在不必深究桥上有什么。")])]),s._v(" "),a("li",[a("p",[a("code",[s._v("Spider")]),s._v("产生的"),a("code",[s._v("Request")]),s._v("对象会经过"),a("code",[s._v("Engine")]),s._v("送入"),a("code",[s._v("Scheduler")]),s._v("调度器中，调度器会将所有"),a("code",[s._v("Request")]),s._v("加入请求队列，一旦可以调度之后，"),a("code",[s._v("Request")]),s._v("就会通过"),a("code",[s._v("Downloader Middlewares")]),s._v("这些桥梁到达"),a("code",[s._v("Downloader")]),s._v("，"),a("code",[s._v("Downloader")]),s._v("就会根据请求内容访问指定的互联网资源，这一过程是异步的。")])]),s._v(" "),a("li",[a("p",[s._v("当"),a("code",[s._v("Downloader")]),s._v("完成一个"),a("code",[s._v("Request")]),s._v("任务后，就会将资源包装成一个"),a("code",[s._v("Response")]),s._v("，里面会包含原"),a("code",[s._v("Request")]),s._v("的信息、封装好的解析器等等，在示例中我们可以看到在"),a("code",[s._v("parse_rank")]),s._v("中抛出的"),a("code",[s._v("Request")]),s._v("携带着"),a("code",[s._v("meta")]),s._v("数据，之后"),a("code",[s._v("meta")]),s._v("继续保存在"),a("code",[s._v("parse_comments")]),s._v("的"),a("code",[s._v("response")]),s._v("里。")])]),s._v(" "),a("li",[a("p",[s._v("此时所有的"),a("code",[s._v("Response")]),s._v("都会再次通过"),a("code",[s._v("Downloader Middlewares")]),s._v("这些桥，再经过"),a("code",[s._v("Engine")]),s._v("以及"),a("code",[s._v("Spider Middlewares")]),s._v("回到所对应的"),a("code",[s._v("Spider")]),s._v("中，并且会激活对应的"),a("code",[s._v("callback")]),s._v("函数，最后就是执行我们编写好的"),a("code",[s._v("parse")]),s._v("方法里的代码。当"),a("code",[s._v("parse")]),s._v("再次抛出"),a("code",[s._v("Request")]),s._v("对象时就会重新执行(3-5)的步骤。")])]),s._v(" "),a("li",[a("p",[s._v("当"),a("code",[s._v("Spider")]),s._v("抛出数据(Item)时，又会再次经过"),a("code",[s._v("Spider Middlewares")]),s._v("到达"),a("code",[s._v("Item Pipeline")]),s._v("，但我们并没有对"),a("code",[s._v("Item Pipeline")]),s._v("指定任何动作因此它只会向外界抛出该"),a("code",[s._v("Item")]),s._v("，之后会被"),a("code",[s._v("logger")]),s._v("捕获这一输出，也就是我们可以看到的控制台有数据产生，由于我们使用了"),a("code",[s._v("-o")]),s._v("指令，因此"),a("code",[s._v("exporter")]),s._v("会将"),a("code",[s._v("item")]),s._v("输出为相应的格式，也就有了我们指定的"),a("code",[s._v("result.json")]),s._v("数据集。")])])]),s._v(" "),a("p",[s._v("到此我们完成了如何使用Scrapy编写一个简单爬虫程序，以及大致了解了Scrapy的工作流程，接下来我们会更加深入的探讨Scrapy的其他组件以及如何利用它们突破反爬机制。")]),s._v(" "),a("p",[s._v("如上述观点有误欢迎雅正！")])])}),[],!1,null,null,null);t.default=e.exports}}]);