---
title : Scrapyåˆ†å¸ƒå¼çˆ¬è™«ï¼Œåˆ†å¸ƒå¼é˜Ÿåˆ—å’Œå¸ƒéš†è¿‡æ»¤å™¨ï¼Œä¸€åˆ†é’Ÿæå®šï¼Ÿ - æ˜é‡‘
description : åœ¨æ­¤å¤„æ·»æè¿°
author : ä¸­ç®­çš„å´èµ·
image : åœ¨æ­¤å¤„æ”¾ä¸Šå›¾ç‰‡é“¾æ¥
date : 2020-08-27 07:45:06 +0800
categories:
 -
tags:
 -
---
[[toc]]
ä½¿ç”¨Scrapyå¼€å‘ä¸€ä¸ªåˆ†å¸ƒå¼çˆ¬è™«ï¼Ÿä½ çŸ¥é“æœ€å¿«çš„æ–¹æ³•æ˜¯ä»€ä¹ˆå—ï¼Ÿä¸€åˆ†é’ŸçœŸçš„èƒ½ å¼€å‘å¥½æˆ–è€…ä¿®æ”¹å‡º ä¸€ä¸ªåˆ†å¸ƒå¼çˆ¬è™«å—ï¼Ÿ

è¯ä¸å¤šè¯´ï¼Œå…ˆè®©æˆ‘ä»¬çœ‹çœ‹æ€ä¹ˆå®è·µï¼Œå†è¯¦ç»†èŠèŠç»†èŠ‚~

å¿«é€Ÿä¸Šæ‰‹
----

### **Step 0:**

é¦–å…ˆå®‰è£… Scrapy-Distributed :

```
pip install scrapy-distributed

```

(éå¿…é¡»)å¦‚æœä½ æ²¡æœ‰æ‰€éœ€è¦çš„è¿è¡Œæ¡ä»¶ï¼Œä½ å¯ä»¥å¯åŠ¨ä¸¤ä¸ª Docker é•œåƒè¿›è¡Œæµ‹è¯• (RabbitMQ å’Œ RedisBloom):

```bash

docker run -d --name rabbitmq -p 0.0.0.0:15672:15672 -p 0.0.0.0:5672:5672 rabbitmq:3

docker run -d --name redis-redisbloom -p 0.0.0.0:6379:6379 redislabs/rebloom:latest
```

### Step 1 (éå¿…é¡»):

å¦‚æœä½ æœ‰ä¸€ä¸ªç°æˆçš„çˆ¬è™«ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸ª Stepï¼Œç›´æ¥åˆ° Step 2ã€‚

åˆ›å»ºä¸€ä¸ªçˆ¬è™«å·¥ç¨‹ï¼Œæˆ‘è¿™é‡Œä»¥ä¸€ä¸ª sitemap çˆ¬è™«ä¸ºä¾‹:

```bash
scrapy startproject simple_example
```

ç„¶åä¿®æ”¹ spiders æ–‡ä»¶å¤¹ä¸‹çš„çˆ¬è™«ç¨‹åºæ–‡ä»¶:

```python
from scrapy_distributed.spiders.sitemap import SitemapSpider
from scrapy_distributed.queues.amqp import QueueConfig
from scrapy_distributed.dupefilters.redis_bloom import RedisBloomConfig

class MySpider(SitemapSpider):
    name = "example"
    sitemap_urls = ["http://www.people.com.cn/robots.txt"]
    queue_conf: QueueConfig = QueueConfig(
        name="example", durable=True, arguments={"x-queue-mode": "lazy", "x-max-priority": 255}
    )
    redis_bloom_conf: RedisBloomConfig = RedisBloomConfig(key="example:dupefilter")

    def parse(self, response):
        self.logger.info(f"parse response, url: {response.url}")
```

### **Step 2:**

åªéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶ settings.py ä¸‹çš„`SCHEDULER`, `DUPEFILTER_CLASS` å¹¶ä¸”æ·»åŠ  RabbitMQ å’Œ Redis çš„ç›¸å…³é…ç½®ï¼Œä½ å°±å¯ä»¥é©¬ä¸Šè·å¾—ä¸€ä¸ªåˆ†å¸ƒå¼çˆ¬è™«ï¼ŒScrapy-Distributed ä¼šå¸®ä½ åˆå§‹åŒ–ä¸€ä¸ªé»˜è®¤é…ç½®çš„ RabbitMQ é˜Ÿåˆ—å’Œä¸€ä¸ªé»˜è®¤é…ç½®çš„ RedisBloom å¸ƒéš†è¿‡æ»¤å™¨ã€‚

```python


SCHEDULER = "scrapy_distributed.schedulers.DistributedScheduler"
SCHEDULER_QUEUE_CLASS = "scrapy_distributed.queues.amqp.RabbitQueue"
RABBITMQ_CONNECTION_PARAMETERS = "amqp://guest:guest@localhost:5672/example/?heartbeat=0"
DUPEFILTER_CLASS = "scrapy_distributed.dupefilters.redis_bloom.RedisBloomDupeFilter"
BLOOM_DUPEFILTER_REDIS_URL = "redis://:@localhost:6379/0"
BLOOM_DUPEFILTER_REDIS_HOST = "localhost"
BLOOM_DUPEFILTER_REDIS_PORT = 6379

REDIS_BLOOM_PARAMS = {
    "redis_cls": "redisbloom.client.Client"
}

BLOOM_DUPEFILTER_ERROR_RATE = 0.001

BLOOM_DUPEFILTER_CAPACITY = 100_0000
```

ä½ ä¹Ÿå¯ä»¥ç»™ä½ çš„ Spider ç±»ï¼Œå¢åŠ ä¸¤ä¸ªç±»å±æ€§ï¼Œæ¥åˆå§‹åŒ–ä½ çš„ RabbitMQ é˜Ÿåˆ—æˆ– RedisBloom å¸ƒéš†è¿‡æ»¤å™¨:

```python
class MySpider(SitemapSpider):
        ......
    
    queue_conf: QueueConfig = QueueConfig(
        name="example", durable=True, arguments={"x-queue-mode": "lazy", "x-max-priority": 255}
    )
    
    redis_bloom_conf: RedisBloomConfig = RedisBloomConfig(key="example:dupefilter", error_rate=0.001, capacity=100_0000)
        ......
```

### **Step 3:**

```
scrapy crawl <your_spider>

```

æ£€æŸ¥ä¸€ä¸‹ä½ çš„ RabbitMQ é˜Ÿåˆ— å’Œ RedisBloom è¿‡æ»¤å™¨ï¼Œæ˜¯ä¸æ˜¯å·²ç»æ­£å¸¸è¿è¡Œäº†ï¼Ÿ

å¯ä»¥çœ‹åˆ°ï¼ŒScrapy-Distributed çš„åŠ æŒä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå°±å¯ä»¥å°†æ™®é€šçˆ¬è™«ä¿®æ”¹æˆæ”¯æŒ RabbitMQ é˜Ÿåˆ— å’Œ RedisBloom å¸ƒéš†è¿‡æ»¤å™¨çš„åˆ†å¸ƒå¼çˆ¬è™«ã€‚åœ¨æ‹¥æœ‰ RabbitMQ å’Œ RedisBloom ç¯å¢ƒçš„æƒ…å†µä¸‹ï¼Œä¿®æ”¹é…ç½®çš„æ—¶é—´ä¹Ÿå°±ä¸€åˆ†é’Ÿã€‚ğŸ˜‚

å…³äºScrapy-Distributed
--------------------

ç›®å‰ Scrapy-Distributed ä¸»è¦å‚è€ƒäº†Scrapy-Redis å’Œ scrapy-rabbitmq è¿™ä¸¤ä¸ªåº“ã€‚

å¦‚æœä½ æœ‰è¿‡ Scrapy çš„ç›¸å…³ç»éªŒï¼Œå¯èƒ½ä¼šçŸ¥é“ Scrapy-Redis è¿™ä¸ªåº“ï¼Œå¯ä»¥å¾ˆå¿«é€Ÿçš„åšåˆ†å¸ƒå¼çˆ¬è™«ï¼Œå¦‚æœä½ å°è¯•è¿‡ä½¿ç”¨ RabbitMQ ä½œä¸ºçˆ¬è™«çš„ä»»åŠ¡é˜Ÿåˆ—ï¼Œä½ å¯èƒ½è¿˜è§åˆ°è¿‡ scrapy-rabbitmq è¿™ä¸ªé¡¹ç›®ã€‚è¯šç„¶ Scrapy-Redis å·²ç»å¾ˆæ–¹ä¾¿äº†ï¼Œscrapy-rabbitmq ä¹Ÿèƒ½å®ç° RabbitMQ ä½œä¸ºä»»åŠ¡é˜Ÿåˆ—ï¼Œä½†æ˜¯ä»–ä»¬å­˜åœ¨ä¸€äº›ç¼ºé™·ï¼Œæˆ‘è¿™é‡Œç®€å•æå‡ºå‡ ä¸ªé—®é¢˜ã€‚

1.  Scrapy-Redis ä½¿ç”¨ Redis çš„ set å»é‡ï¼Œé“¾æ¥æ•°é‡è¶Šå¤§å ç”¨çš„å†…å­˜å°±è¶Šå¤§ï¼Œä¸é€‚åˆä»»åŠ¡æ•°é‡å¤§çš„åˆ†å¸ƒå¼çˆ¬è™«ã€‚
2.  Scrapy-Redis ä½¿ç”¨ Redis çš„ list ä½œä¸ºé˜Ÿåˆ—ï¼Œå¾ˆå¤šåœºæ™¯ä¼šæœ‰ä»»åŠ¡ç§¯å‹ï¼Œä¼šå¯¼è‡´å†…å­˜èµ„æºæ¶ˆè€—è¿‡å¿«ï¼Œæ¯”å¦‚æˆ‘ä»¬çˆ¬å–ç½‘ç«™ sitemap æ—¶ï¼Œé“¾æ¥å…¥é˜Ÿçš„é€Ÿåº¦è¿œè¿œå¤§äºå‡ºé˜Ÿã€‚
3.  scrapy-rabbitmq ç­‰ RabbitMQ çš„ Scrapy ç»„ä»¶ï¼Œåœ¨åˆ›å»ºé˜Ÿåˆ—æ–¹é¢ï¼Œæ²¡æœ‰æä¾› RabbitMQ æ”¯æŒçš„å„ç§å‚æ•°ï¼Œæ— æ³•æ§åˆ¶é˜Ÿåˆ—çš„æŒä¹…åŒ–ç­‰å‚æ•°ã€‚
4.  scrapy-rabbitmq ç­‰ rabbitmq æ¡†æ¶çš„ Scheduler æš‚æœªæ”¯æŒåˆ†å¸ƒå¼çš„ dupefilter ï¼Œéœ€è¦ä½¿ç”¨è€…è‡ªè¡Œå¼€å‘æˆ–æ¥å…¥ç›¸å…³ç»„ä»¶ã€‚
5.  Scrapy-Redis å’Œ scrapy-rabbitmq ç­‰æ¡†æ¶éƒ½æ˜¯ä¾µå…¥å¼çš„ï¼Œå¦‚æœéœ€è¦ç”¨è¿™äº›æ¡†æ¶å¼€å‘åˆ†å¸ƒå¼çš„çˆ¬è™«ï¼Œéœ€è¦æˆ‘ä»¬ä¿®æ”¹è‡ªå·±çš„çˆ¬è™«ä»£ç ï¼Œé€šè¿‡ç»§æ‰¿æ¡†æ¶çš„ Spider ç±»ï¼Œæ‰èƒ½å®ç°åˆ†å¸ƒå¼åŠŸèƒ½ã€‚

äºæ˜¯ï¼ŒScrapy-Distributed æ¡†æ¶å°±åœ¨è¿™ä¸ªæ—¶å€™è¯ç”Ÿäº†ï¼Œåœ¨éä¾µå…¥å¼è®¾è®¡ä¸‹ï¼Œä½ åªéœ€è¦é€šè¿‡ä¿®æ”¹ settings.py ä¸‹çš„é…ç½®ï¼Œæ¡†æ¶å°±å¯ä»¥æ ¹æ®é»˜è®¤é…ç½®å°†ä½ çš„çˆ¬è™«åˆ†å¸ƒå¼åŒ–ã€‚

ä¸ºäº†è§£å†³Scrapy-Redis å’Œ scrapy-rabbitmq å­˜åœ¨çš„ä¸€äº›ç—›ç‚¹ï¼ŒScrapy-Distributed åšäº†ä¸‹é¢å‡ ä»¶äº‹:

1.  é‡‡ç”¨äº† RedisBloom çš„å¸ƒéš†è¿‡æ»¤å™¨ï¼Œå†…å­˜å ç”¨æ›´å°‘ã€‚
2.  æ”¯æŒäº† RabbitMQ é˜Ÿåˆ—å£°æ˜çš„æ‰€æœ‰å‚æ•°é…ç½®ï¼Œå¯ä»¥è®© RabbitMQ é˜Ÿåˆ—æ”¯æŒ lazy-mode æ¨¡å¼ï¼Œå°†å‡å°‘å†…å­˜å ç”¨ã€‚
3.  RabbitMQ çš„é˜Ÿåˆ—å£°æ˜æ›´åŠ çµæ´»ï¼Œä¸åŒçˆ¬è™«å¯ä»¥ä½¿ç”¨ç›¸åŒé˜Ÿåˆ—é…ç½®ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ä¸åŒçš„é˜Ÿåˆ—é…ç½®ã€‚
4.  Scheduler çš„è®¾è®¡ä¸Šæ”¯æŒå¤šä¸ªç»„ä»¶çš„æ­é…ç»„åˆï¼Œå¯ä»¥å•ç‹¬ä½¿ç”¨ RedisBloom çš„DupeFilterï¼Œä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ RabbitMQ çš„ Scheduler æ¨¡å—ã€‚
5.  å®ç°äº† Scrapy åˆ†å¸ƒå¼åŒ–çš„éä¾µå…¥å¼è®¾è®¡ï¼Œåªéœ€è¦ä¿®æ”¹é…ç½®ï¼Œå°±å¯ä»¥å°†æ™®é€šçˆ¬è™«åˆ†å¸ƒå¼åŒ–ã€‚

ç›®å‰æ¡†æ¶è¿˜æœ‰å¾ˆå¤šåŠŸèƒ½æ­£åœ¨æ·»åŠ ï¼Œæ„Ÿå…´è¶£çš„å°ä¼™ä¼´å¯ä»¥æŒç»­å…³æ³¨é¡¹ç›®ä»“åº“çš„åŠ¨å‘ï¼Œæœ‰ä»€ä¹ˆæƒ³æ³•ä¹Ÿå¯ä»¥ä¸€èµ·è®¨è®ºã€‚

Scrapy-Distributed çš„ github ä»“åº“åœ°å€ï¼š[github.com/Insutanto/sâ€¦](https://github.com/Insutanto/scrapy-distributed)

åšå®¢åœ°å€ï¼š[insutanto.net/posts/scrapâ€¦](https://insutanto.net/posts/scrapy/)